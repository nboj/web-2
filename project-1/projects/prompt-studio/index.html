<!doctype html>
<html lang="en">
  <head>
    <title>Prompt Studio - Christian Auman</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-sRIl4kxILFvY47J16cr9ZwB07vP4J8+LH7qKQnuqkuIAvNWLzeN8tE5YBujZqJLB"
      crossorigin="anonymous"
    />
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-FKyoEForCGlyvwx9Hj09JcYn3nv7wiPVlz7YYwJrWVcXK/BmnVDxM+D2scQbITxI"
      crossorigin="anonymous"
    ></script>
    <script src="../../components/navbar.js" type="module"></script>
    <script src="../../components/footer.js" type="module"></script>
    <script src="../../components/project-template.js" type="module"></script>
    <link href="../../styles.css" rel="stylesheet"></link>
  </head>
  <body>
    <main>
      <portfolio-navbar></portfolio-navbar>
      
      <project-template
        title="Prompt Studio"
        subtitle="Diffusion Attribution Attention Maps for Text-to-Image Understanding"
        image="../../images/prompt-studio.png"
        tags="Python, Rust, PyTorch, Next.js, TypeScript, DAAM"
        code-link="https://github.com/nboj/research">
        
        <div slot="overview">
          <p>
            Prompt Studio extends my previous research on explainable AI for text-to-image generation by implementing 
            Diffusion Attribution Attention Maps (DAAM). This tool provides deeper insights into how diffusion models 
            understand the relationship between text prompts and generated images.
          </p>
          <p>
            By visualizing attention patterns throughout the diffusion process, Prompt Studio helps users understand 
            not just which words matter, but <em>when</em> and <em>how</em> they influence the image generation. We also provided a way to construct your prompts with category selectors, allowing you to improve your prompt dramatically without actually having any expertise in prompt building and/or generative models.
          </p>
        </div>

        <div slot="challenge">
          <p>
            While my previous LRP implementation provided valuable insights into token relevance, it had limitations:
          </p>
          <ul>
            <li>Relevance scores were computed only for the final output, missing the temporal dynamics of diffusion</li>
            <li>The relationship between text tokens and spatial image regions wasn't explicit enough</li>
            <li>Users couldn't see how attention patterns evolved throughout the denoising process</li>
            <li>Performance bottlenecks in Python made real-time exploration difficult for complex prompts</li>
          </ul>
        </div>

        <div slot="solution">
          <p>
            Prompt Studio addresses these challenges through a hybrid Rust/Python architecture and advanced attention mapping:
          </p>
          <ul>
            <li><strong>DAAM Integration:</strong> Implemented Diffusion Attribution Attention Maps to track how attention to each token changes across diffusion timesteps</li>
            <li><strong>Rust Performance Layer:</strong> Built critical computation paths in Rust for 10x faster attention map generation</li>
            <li><strong>Temporal Visualization:</strong> Created interactive timeline controls to scrub through the diffusion process and see attention evolution</li>
            <li><strong>Enhanced Web Interface:</strong> Upgraded the Next.js frontend with advanced visualization components for multi-dimensional attention data</li>
          </ul>
        </div>

        <div slot="features">
          <div class="feature-grid">
            <div class="feature-card">
              <h4>Timestep Scrubbing</h4>
              <p>Navigate through the diffusion process to see how attention patterns change over time</p>
            </div>
            <div class="feature-card">
              <h4>Spatial Attention Maps</h4>
              <p>Visualize exactly which image regions each text token influences at any timestep</p>
            </div>
            <div class="feature-card">
              <h4>Multi-Token Analysis</h4>
              <p>Compare attention patterns across multiple tokens simultaneously with layered heatmaps</p>
            </div>
            <div class="feature-card">
              <h4>Export & Share</h4>
              <p>Save attention visualizations and share findings with researchers or collaborators</p>
            </div>
            <div class="feature-card">
              <h4>Rust-Powered Performance</h4>
              <p>Real-time computation of attention maps even for complex, multi-object prompts</p>
            </div>
            <div class="feature-card">
              <h4>Token Relationship Graph</h4>
              <p>Understand how tokens interact and influence each other during generation</p>
            </div>
          </div>
        </div>

        <div slot="technical">
          <h3>DAAM Implementation</h3>
          <p>
            The Diffusion Attribution Attention Maps implementation required:
          </p>
          <ul>
            <li>Hooking into Stable Diffusion's cross-attention layers at each timestep</li>
            <li>Accumulating attention weights across multiple attention heads</li>
            <li>Upsampling and aligning attention maps to match image resolution</li>
            <li>Normalizing attention scores across timesteps for fair comparison</li>
          </ul>

          <h3>Advanced Visualization Pipeline</h3>
          <p>
            The Next.js frontend handles complex multi-dimensional data:
          </p>
          <ul>
            <li><strong>A/B Comparisons:</strong> Implemented A/B comparisons to analyze any small change you make to the prompt</li>
            <li><strong>Interactive Comparisons:</strong> For each comparison, you can click on tokens int he prompt to render their individual heatmap which lets users understand and interpret the model's "mind"</li>
            <li><strong>Programmatic Prompt Construction:</strong> Implemented a "Prompt Builder" architecture which combines your category selectors into your raw prompt in a way that Stable Diffusion can understand. It does this with either a LLM, or with my small algorithm.</li>
          </ul>
        </div>


          <div class="highlight-box">
            <h3>Novel Discoveries</h3>
            <p>
              Using Prompt Studio, we discovered that the way in which you construct your prompt (not just your words) matters significantly. We have a case study on one of our seeds where we changed one word and it generated unwanted artifacts. We were able to get what we wanted by changing the structure of the prompt which improved the result dramatically. We also have proved that the category selectors are effective in improving results.
            </p>
          </div>
        </div>

        <div slot="">
          <div class="section">
            <h2>Future Directions</h2>
            <p>
              Planned enhancements for Prompt Studio include:
            </p>
            <ul>
              <li>Support for analyzing video diffusion models frame-by-frame</li>
              <li>Comparative visualization showing attention differences between model versions</li>
              <li>AI-powered prompt suggestions based on attention pattern analysis</li>
              <li>Integration with other explainability techniques like GradCAM and SHAP</li>
            </ul>
          </div>
        </div>
      </project-template>

      <portfolio-footer></portfolio-footer>
    </main>
  </body>
</html>
